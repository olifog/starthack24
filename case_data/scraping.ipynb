{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "177443ea-0d57-4a5d-90c8-ea65a32e4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from os import mkdir\n",
    "from os.path import join, exists\n",
    "import json\n",
    "from time import sleep\n",
    "from tqdm import tqdm \n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "# urls to base webpages on sg.ch\n",
    "\n",
    "base = [\n",
    "    \"https://www.sg.ch/ueber-den-kanton-st-gallen.html\",\n",
    "    \"https://www.sg.ch/politik-verwaltung.html\",\n",
    "    \"https://www.sg.ch/bauen.html\",\n",
    "    \"https://www.sg.ch/bildung-sport.html\",\n",
    "    \"https://www.sg.ch/gesundheit-soziales.html\",\n",
    "    \"https://www.sg.ch/kultur.html\",\n",
    "    \"https://www.sg.ch/recht.html\",\n",
    "    \"https://www.sg.ch/sicherheit.html\",\n",
    "    \"https://www.sg.ch/steuern-finanzen.html\",\n",
    "    \"https://www.sg.ch/umwelt-natur.html\",\n",
    "    \"https://www.sg.ch/verkehr.html\",\n",
    "    \"https://www.sg.ch/wirtschaft-arbeit.html\",    \n",
    "]\n",
    "\n",
    "data_dir = \"data\"\n",
    "\n",
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd7381f-04ad-4265-8b83-fd8394070fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import join\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# collecting a mapping from dir withiin `data_dir` to source link to the HTML page from sg.ch\n",
    "\n",
    "all_source2base_ = {}\n",
    "\n",
    "def recursive_scrap(links: list, all_source2base: dict):\n",
    "    source2base = {\n",
    "        link.replace(\"https://www.sg.ch/\", \"\").replace(\".html\", \"\"): link \n",
    "        for link in links\n",
    "    }\n",
    "    all_source2base = {**all_source2base, **source2base}\n",
    "    for source, link in source2base.items():\n",
    "        if not exists(join(data_dir, source)):\n",
    "            makedirs(join(data_dir, source))\n",
    "        data_path = join(data_dir, source, \"data.html\")\n",
    "        if not exists(data_path):\n",
    "            with open(data_path, \"w\") as f:\n",
    "                try:\n",
    "                    content = requests.get(\n",
    "                        link, \n",
    "                        headers={'User-Agent': ua.chrome} # to avoid the ban \n",
    "                    ).text\n",
    "                except:\n",
    "                    sleep(10)\n",
    "                    continue\n",
    "                f.write(content)\n",
    "                sleep(0.2)\n",
    "        subpages = []\n",
    "        with open(data_path, \"r\") as f:\n",
    "            content = f.read()\n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "            for e in soup.find_all(\"a\"):\n",
    "                href = e.attrs.get(\"href\", \"\")\n",
    "                if f\"/{source}/\" in href and \".html\" in href:\n",
    "                    if \"/content/sgch/\" in href:\n",
    "                        href = href.replace(\"content/sgch/\", \"\")\n",
    "                    subpages.append(\n",
    "                        f\"https://www.sg.ch{href}\" \n",
    "                        if \"https://www.sg.ch\" not in href \n",
    "                        else href\n",
    "                    )\n",
    "            subpages = list(set(subpages))\n",
    "            all_source2base = recursive_scrap(subpages, all_source2base)\n",
    "    return all_source2base\n",
    "\n",
    "# the only reason to do such loop is to monitor progress via tqdm\n",
    "for url in tqdm(base):\n",
    "    all_source2base_ = recursive_scrap([url], all_source2base=all_source2base_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ce12e9b-3ff8-497b-92ee-41eaaea0b4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3879/3879 [06:27<00:00, 10.01it/s]\n"
     ]
    }
   ],
   "source": [
    "if not exists(\"sourve2link.jsonl\"):\n",
    "    with open(\"sourve2link.jsonl\", \"w\") as f:\n",
    "        for path_to_data, link in tqdm(all_source2base_.items()):\n",
    "            path = join(data_dir, path_to_data, \"data.html\")\n",
    "            voice_url = None\n",
    "            with open(path, \"r\") as g:\n",
    "                soup = BeautifulSoup(g.read(), 'html.parser')\n",
    "                for e in soup.find_all(\"a\"):\n",
    "                    href = e.attrs.get(\"href\", \"\")\n",
    "                    if \"//app-eu.readspeaker.com/cgi-bin\" in href: # the url to the voice recording\n",
    "                        voice_url = f\"https:{href.replace('amp;','')}\"\n",
    "            f.write(\n",
    "                json.dumps({\n",
    "                    \"source\": link, \n",
    "                    \"path\": join(data_dir, path_to_data), \n",
    "                    \"voice_url\": voice_url\n",
    "                }) + \"\\n\")\n",
    "\n",
    "data = []\n",
    "with open(\"sourve2link.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d91a979-b313-4ce6-8d18-fecf701a22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(data).to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19222e0-610c-47ff-b87f-ab118a0addc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
